{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYhB_XcsaRgA"
      },
      "outputs": [],
      "source": [
        "# Required imports\n",
        "import torch\n",
        "from fairseq2.models.transformer import TransformerDecoderModel\n",
        "from fairseq2.data import VocabularyInfo\n",
        "from fairseq2.nn.utils.module import infer_device\n",
        "import fairseq2.data as f2_data\n",
        "import os\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "class LCMProcessor:\n",
        "    def __init__(self, sonar_model_name=\"facebook/sonar-small\", device=None):\n",
        "        \"\"\"Initialize LCM processor with SONAR embeddings\"\"\"\n",
        "        self.device = device or infer_device()\n",
        "\n",
        "        # Initialize SONAR for embeddings\n",
        "        self.sonar = torch.hub.load('facebookresearch/sonar', sonar_model_name)\n",
        "        self.sonar.to(self.device)\n",
        "\n",
        "        # Set up normalizer config\n",
        "        self.normalizer_config = {\n",
        "            \"mean\": 0.0,\n",
        "            \"std\": 1.0,\n",
        "            \"clip_value\": 5.0\n",
        "        }\n",
        "\n",
        "    def prepare_data(self, text_data, output_dir):\n",
        "        \"\"\"Process text data into SONAR embeddings\"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        embeddings = []\n",
        "        for text in text_data:\n",
        "            # Get SONAR embeddings\n",
        "            with torch.no_grad():\n",
        "                emb = self.sonar.encode(text)\n",
        "                embeddings.append(emb)\n",
        "\n",
        "        # Save embeddings\n",
        "        embeddings_path = Path(output_dir) / \"embeddings.pt\"\n",
        "        torch.save(torch.stack(embeddings), embeddings_path)\n",
        "\n",
        "        # Create datacard\n",
        "        datacard = {\n",
        "            \"name\": \"lcm_dataset\",\n",
        "            \"paths\": {\n",
        "                \"embeddings\": str(embeddings_path)\n",
        "            },\n",
        "            \"schema\": {\n",
        "                \"embedding_dim\": embeddings[0].shape[-1]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open(Path(output_dir) / \"datacard.yaml\", \"w\") as f:\n",
        "            yaml.dump(datacard, f)\n",
        "\n",
        "        return embeddings_path\n",
        "\n",
        "class LCMTrainer:\n",
        "    def __init__(self, model_config, output_dir):\n",
        "        \"\"\"Initialize LCM trainer\"\"\"\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.model_config = model_config\n",
        "\n",
        "        # Create model architecture\n",
        "        self.model = self._create_model()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters())\n",
        "\n",
        "    def _create_model(self):\n",
        "        \"\"\"Create LCM model architecture\"\"\"\n",
        "        model = TransformerDecoderModel(\n",
        "            vocab_info=VocabularyInfo(len(self.model_config[\"vocab_size\"])),\n",
        "            num_layers=self.model_config.get(\"num_layers\", 12),\n",
        "            model_dim=self.model_config.get(\"model_dim\", 768),\n",
        "            num_heads=self.model_config.get(\"num_heads\", 12),\n",
        "            ffn_dim=self.model_config.get(\"ffn_dim\", 3072),\n",
        "            max_seq_len=self.model_config.get(\"max_seq_len\", 512)\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def train(self, train_embeddings, val_embeddings=None, num_epochs=10):\n",
        "        \"\"\"Train the LCM model\"\"\"\n",
        "        self.model.train()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            total_loss = 0\n",
        "\n",
        "            # Training loop\n",
        "            for batch in self._get_batches(train_embeddings):\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                output = self.model(batch)\n",
        "                loss = torch.nn.functional.mse_loss(output, batch)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            # Save checkpoint\n",
        "            if (epoch + 1) % 5 == 0:\n",
        "                self._save_checkpoint(epoch)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}, Loss: {total_loss}\")\n",
        "\n",
        "    def _get_batches(self, embeddings, batch_size=32):\n",
        "        \"\"\"Create batches from embeddings\"\"\"\n",
        "        dataset = torch.utils.data.TensorDataset(embeddings)\n",
        "        dataloader = torch.utils.data.DataLoader(\n",
        "            dataset, batch_size=batch_size, shuffle=True\n",
        "        )\n",
        "        return dataloader\n",
        "\n",
        "    def _save_checkpoint(self, epoch):\n",
        "        \"\"\"Save model checkpoint\"\"\"\n",
        "        checkpoint_dir = self.output_dir / f\"checkpoint_{epoch}\"\n",
        "        checkpoint_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Save model\n",
        "        torch.save(self.model.state_dict(), checkpoint_dir / \"model.pt\")\n",
        "\n",
        "        # Save config\n",
        "        with open(checkpoint_dir / \"config.yaml\", \"w\") as f:\n",
        "            yaml.dump(self.model_config, f)\n",
        "\n",
        "# Example usage\n",
        "def train_lcm(text_data, output_dir):\n",
        "    # Initialize processor\n",
        "    processor = LCMProcessor()\n",
        "\n",
        "    # Process data\n",
        "    embeddings_path = processor.prepare_data(text_data, output_dir)\n",
        "\n",
        "    # Model configuration\n",
        "    model_config = {\n",
        "        \"vocab_size\": 32000,\n",
        "        \"num_layers\": 12,\n",
        "        \"model_dim\": 768,\n",
        "        \"num_heads\": 12,\n",
        "        \"ffn_dim\": 3072,\n",
        "        \"max_seq_len\": 512\n",
        "    }\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = LCMTrainer(model_config, output_dir)\n",
        "\n",
        "    # Load embeddings\n",
        "    embeddings = torch.load(embeddings_path)\n",
        "\n",
        "    # Train model\n",
        "    trainer.train(embeddings)"
      ]
    }
  ]
}